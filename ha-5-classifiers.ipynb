{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from string import punctuation as en_punc\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aux/stop-words.txt') as f:\n",
    "    STOP_WORDS = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wb_title</th>\n",
       "      <th>wb_body</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>တရုတ် သမ္မတ ခရီးစဉ် က သမုဒ္ဒရာ ၂ စင်း သေနင်္ဂဗ...</td>\n",
       "      <td>တရုတ် သမ္မတ ရှီ ကျင့် ဖျင် သည် သမ္မတ ဦး ဝင်း မ...</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>တရုတ် သမ္မတ ရဲ့ ခရီး ရှည် ချီတက် ပွဲ သစ်</td>\n",
       "      <td>၁၉၃၄ မှ ၁၉၃၆ အတွင်း ခရီး ရှည် ချီတက် ပွဲ စတင် ...</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ရက္ခိုင် ပြည် သူ့ အာဏာပိုင်အဖွဲ့ ကို ထူထောင် တ...</td>\n",
       "      <td>အစိုးရ နှင့် မြောက် ပိုင်း မဟာမိတ် တပ်ဖွဲ့ တွေ...</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>အစိုးရ နှင့် မြောက် ပိုင်း မဟာမိတ် ဆွေးနွေးပွဲ...</td>\n",
       "      <td>အစိုးရ ငြိမ်းချမ်းရေး ကိုယ်စားလှယ် များ နှင့် ...</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ရဲဘော်သုံးကျိပ် ဝင် မိသားစု များ ၏ မိတ်ဆုံ စား...</td>\n",
       "      <td>၃၂ ကြိမ် မြောက် ရဲဘော်သုံးကျိပ် မိသားစု သာရေးန...</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            wb_title  \\\n",
       "0  တရုတ် သမ္မတ ခရီးစဉ် က သမုဒ္ဒရာ ၂ စင်း သေနင်္ဂဗ...   \n",
       "1           တရုတ် သမ္မတ ရဲ့ ခရီး ရှည် ချီတက် ပွဲ သစ်   \n",
       "2  ရက္ခိုင် ပြည် သူ့ အာဏာပိုင်အဖွဲ့ ကို ထူထောင် တ...   \n",
       "3  အစိုးရ နှင့် မြောက် ပိုင်း မဟာမိတ် ဆွေးနွေးပွဲ...   \n",
       "4  ရဲဘော်သုံးကျိပ် ဝင် မိသားစု များ ၏ မိတ်ဆုံ စား...   \n",
       "\n",
       "                                             wb_body site  \n",
       "0  တရုတ် သမ္မတ ရှီ ကျင့် ဖျင် သည် သမ္မတ ဦး ဝင်း မ...  irr  \n",
       "1  ၁၉၃၄ မှ ၁၉၃၆ အတွင်း ခရီး ရှည် ချီတက် ပွဲ စတင် ...  irr  \n",
       "2  အစိုးရ နှင့် မြောက် ပိုင်း မဟာမိတ် တပ်ဖွဲ့ တွေ...  irr  \n",
       "3  အစိုးရ ငြိမ်းချမ်းရေး ကိုယ်စားလှယ် များ နှင့် ...  irr  \n",
       "4  ၃၂ ကြိမ် မြောက် ရဲဘော်သုံးကျိပ် မိသားစု သာရေးန...  irr  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "irr = pd.read_csv('data/clean_wb/irr.csv', sep='\\t', usecols=['wb_title','wb_body'])\n",
    "ele = pd.read_csv('data/clean_wb/ele.csv', sep='\\t', usecols=['wb_title','wb_body'])\n",
    "miz = pd.read_csv('data/clean_wb/miz.csv', sep='\\t', usecols=['wb_title','wb_body'])\n",
    "voi = pd.read_csv('data/clean_wb/voi.csv', sep='\\t', usecols=['wb_title','wb_body'])\n",
    "dvb = pd.read_csv('data/clean_wb/dvb.csv', sep='\\t', usecols=['wb_title','wb_body'])\n",
    "\n",
    "irr['site'] = 'irr'\n",
    "ele['site'] = 'ele'\n",
    "miz['site'] = 'miz'\n",
    "voi['site'] = 'voi'\n",
    "dvb['site'] = 'dvb'\n",
    "\n",
    "df = pd.concat([irr,ele,miz,voi,dvb])\n",
    "df['wb_title'] = [\n",
    "    str(text).translate(str.maketrans('', '', en_punc)) for text in df.wb_title]\n",
    "df['wb_body'] = [\n",
    "    str(text).translate(str.maketrans('', '', en_punc)) for text in df.wb_body]\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Statistical Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train, title_test, body_train, body_test, site_train, site_test = train_test_split(\n",
    "    df.wb_title.values, df.wb_body.values, df.site.values, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vectorizer = TfidfVectorizer(tokenizer=lambda x:x.split(), stop_words=STOP_WORDS)\n",
    "title_train_vec = title_vectorizer.fit_transform(title_train)\n",
    "title_test_vec = title_vectorizer.transform(title_test)\n",
    "\n",
    "body_vectorizer = TfidfVectorizer(tokenizer=lambda x:x.split(), stop_words=STOP_WORDS)\n",
    "body_train_vec = body_vectorizer.fit_transform(body_train)\n",
    "body_test_vec = body_vectorizer.transform(body_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using article titles: 0.52\n",
      "Accuracy using article bodies: 0.6\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(title_train_vec, site_train)\n",
    "print('Accuracy using article titles:', lr.score(title_test_vec, site_test))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(body_train_vec, site_train)\n",
    "print('Accuracy using article bodies:', lr.score(body_test_vec, site_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotenc = OneHotEncoder()\n",
    "onehot_site_train = onehotenc.fit_transform(site_train.reshape(-1, 1))\n",
    "onehot_site_test = onehotenc.transform(site_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN using Article Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 10)                11250     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 11,305\n",
      "Trainable params: 11,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = title_train_vec.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "# Simple perceptron\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=tf.losses.categorical_crossentropy, \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Train on 200 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 1.6108 - accuracy: 0.1800\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 961us/sample - loss: 1.6028 - accuracy: 0.3050\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/sample - loss: 1.5953 - accuracy: 0.4750\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 878us/sample - loss: 1.5866 - accuracy: 0.5650\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/sample - loss: 1.5752 - accuracy: 0.6800\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/sample - loss: 1.5604 - accuracy: 0.7600\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.5419 - accuracy: 0.83 - 0s 973us/sample - loss: 1.5417 - accuracy: 0.8300\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 669us/sample - loss: 1.5183 - accuracy: 0.8800\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/sample - loss: 1.4921 - accuracy: 0.9400\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 1ms/sample - loss: 1.4626 - accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(title_train_vec, onehot_site_train,\n",
    "                    epochs=10,\n",
    "                    verbose=True,\n",
    "                    batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Training Accuracy: 0.9700\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Testing Accuracy:  0.5000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(title_train_vec, onehot_site_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(title_test_vec, onehot_site_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN using Article Bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 10)                83690     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 83,745\n",
      "Trainable params: 83,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = body_train_vec.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=tf.losses.categorical_crossentropy, \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Train on 200 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 3ms/sample - loss: 1.6061 - accuracy: 0.3050\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 1ms/sample - loss: 1.5830 - accuracy: 0.5050\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 1.5479 - accuracy: 0.7350\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/sample - loss: 1.5041 - accuracy: 0.9450\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 1.4557 - accuracy: 0.9750\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/sample - loss: 1.4016 - accuracy: 0.9850\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 1.3433 - accuracy: 0.9800\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 1.2796 - accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/sample - loss: 1.2105 - accuracy: 0.9900\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 884us/sample - loss: 1.1379 - accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(body_train_vec, onehot_site_train,\n",
    "                    epochs=10,\n",
    "                    verbose=True,\n",
    "                    batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Training Accuracy: 0.9950\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Testing Accuracy:  0.3000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(body_train_vec, onehot_site_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(body_test_vec, onehot_site_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
