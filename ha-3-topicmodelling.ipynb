{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POC\n",
    "<https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gensim import corpora\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from string import punctuation as en_punc\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [\n",
    "    ['နေကောင်း','လား'],\n",
    "    ['သွား','စား','မယ်'],\n",
    "    ['ဖုန်း','ပြော','နေ','တယ်']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "pickle.dump(corpus, open('aux/corpus.pkl', 'wb'))\n",
    "dictionary.save('aux/dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.176*\"မယ်\" + 0.176*\"သွား\" + 0.176*\"စား\" + 0.176*\"နေကောင်း\"')\n",
      "(1, '0.111*\"နေကောင်း\" + 0.111*\"လား\" + 0.111*\"စား\" + 0.111*\"သွား\"')\n",
      "(2, '0.207*\"ပြော\" + 0.207*\"ဖုန်း\" + 0.207*\"နေ\" + 0.207*\"တယ်\"')\n",
      "(3, '0.111*\"လား\" + 0.111*\"နေကောင်း\" + 0.111*\"စား\" + 0.111*\"မယ်\"')\n",
      "(4, '0.111*\"လား\" + 0.111*\"နေကောင်း\" + 0.111*\"စား\" + 0.111*\"သွား\"')\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(\n",
    "    corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('aux/model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POC DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aux/stop-words.txt') as f:\n",
    "    STOP_WORDS = [l.strip() for l in f]\n",
    "\n",
    "def tokenize(text): # Assumes the text is already word-segmented and is space-separated\n",
    "    return text.split()\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    text = text.translate(str.maketrans('', '', en_punc))\n",
    "    tokens = tokenize(text)\n",
    "#     tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in STOP_WORDS]\n",
    "#     tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "irr = pd.read_csv('data/clean_wb/irr.csv', sep='\\t', usecols=['wb_title','wb_body'])\n",
    "ele = pd.read_csv('data/clean_wb/ele.csv', sep='\\t', usecols=['wb_title','wb_body'])\n",
    "miz = pd.read_csv('data/clean_wb/miz.csv', sep='\\t', usecols=['wb_title','wb_body'])\n",
    "voi = pd.read_csv('data/clean_wb/voi.csv', sep='\\t', usecols=['wb_title','wb_body'])\n",
    "dvb = pd.read_csv('data/clean_wb/dvb.csv', sep='\\t', usecols=['wb_title','wb_body'])\n",
    "text_data = [\n",
    "    prepare_text_for_lda(t) for t in irr.wb_body.values] + [\n",
    "    prepare_text_for_lda(t) for t in ele.wb_body.values] + [\n",
    "    prepare_text_for_lda(t) for t in miz.wb_body.values] + [\n",
    "    prepare_text_for_lda(t) for t in voi.wb_body.values] + [\n",
    "    prepare_text_for_lda(t) for t in dvb.wb_body.values]\n",
    "print(len(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "pickle.dump(corpus, open('aux/all_body_corpus.pkl', 'wb'))\n",
    "dictionary.save('aux/all_body_dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.014*\"အလုပ်သမား\" + 0.006*\"ကန်\" + 0.006*\"ကျောက်ကပ်\" + 0.006*\"ဘတ်\" + 0.006*\"ဖို့\" + 0.006*\"လို့\"')\n",
      "(1, '0.015*\"တစ်\" + 0.012*\"ဆို\" + 0.009*\"လို့\" + 0.008*\"ပဲ\" + 0.008*\"သွား\" + 0.007*\"နှစ်\"')\n",
      "(2, '0.010*\"နိုင်\" + 0.009*\"ထား\" + 0.008*\"ပေး\" + 0.007*\"ဟု\" + 0.007*\"ကုန်\" + 0.007*\"အတွက်\"')\n",
      "(3, '0.027*\"႔\" + 0.021*\"တြ\" + 0.014*\"တယ္\" + 0.012*\"န\" + 0.010*\"မွာ\" + 0.009*\"ၾ\"')\n",
      "(4, '0.016*\"ယ\" + 0.009*\"တ\" + 0.008*\"လေး\" + 0.007*\"တစ်\" + 0.007*\"ဘူး\" + 0.007*\"ဆို\"')\n",
      "(5, '0.010*\"ပါတီ\" + 0.010*\"တစ်\" + 0.009*\"ဟု\" + 0.009*\"နိုင်\" + 0.008*\"မည်\" + 0.007*\"ဖြင့်\"')\n",
      "(6, '0.010*\"ရာခိုင်နှုန်း\" + 0.009*\"နှစ်\" + 0.009*\"ဒသမ\" + 0.008*\"နှုန်း\" + 0.007*\"ဆန်\" + 0.007*\"ခုနှစ်\"')\n",
      "(7, '0.028*\"ဆို\" + 0.021*\"လို့\" + 0.017*\"ရင်\" + 0.017*\"ဘူး\" + 0.016*\"ပဲ\" + 0.014*\"မယ်\"')\n",
      "(8, '0.023*\"တရုတ်\" + 0.018*\"နိုင်ငံ\" + 0.013*\"တ\" + 0.009*\"နိုင်\" + 0.009*\"မြန်မာနိုင်ငံ\" + 0.008*\"စီမံကိန်း\"')\n",
      "(9, '0.029*\"င\" + 0.025*\"တ\" + 0.023*\"ဈ\" + 0.023*\"သ\" + 0.020*\"န\" + 0.016*\"တှ\"')\n",
      "10.42266058921814\n"
     ]
    }
   ],
   "source": [
    "# The top 10 topics\n",
    "t0 = time()\n",
    "NUM_TOPICS = 10\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(\n",
    "    corpus, num_topics=NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('aux/all_body_model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=6)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['တရုတ်', 'သမ္မတ', 'ခရီးစဉ်', 'သမုဒ္ဒရာ', '၂', 'စင်း', 'သေနင်္ဂဗျူဟာ', 'တွန်းအားပေး', 'ရည်ရွယ်']\n",
      "[(0, 0.01000337), (1, 0.010003742), (2, 0.90996426), (3, 0.010003752), (4, 0.010003204), (5, 0.010004098), (6, 0.010002954), (7, 0.010004617), (8, 0.010006982), (9, 0.010003059)]\n"
     ]
    }
   ],
   "source": [
    "# Sample topic extraction for first title\n",
    "new_doc = irr.wb_title[0]\n",
    "new_doc = prepare_text_for_lda(new_doc)\n",
    "new_doc_bow = dictionary.doc2bow(new_doc)\n",
    "print(new_doc)\n",
    "print(ldamodel.get_document_topics(new_doc_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The list of tuples represents the topics and their associated probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
